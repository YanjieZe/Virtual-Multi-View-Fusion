dataset:
  root_path: /data/ScanNetV2
  train_path: /data/ScanNetV2/scans
  test_path: /data/ScanNetV2/scans_test
  label_map: /data/ScanNetV2/scannetv2-labels.combined.tsv
  image_form: color
  real_view: True # this means we use real view, not virtual view
  image_num_percentage: 1.0 # from 0 to 1, to sample image from the image dataset


device: "cuda:0"

  
model:
  model_name: deeplabv3+ # choice: unet, deeplabv3+

  # --------------if model is deeplabv3+------------------#
  backbone: xception # choice: resnet, drn, mobilenet, xception
  # ------------------------------------------------------#

  pretrain: False
  pretrained_model_path: /home/yanjie/zyj_test/virtual-multi-view/checkpoint/???
  # mobilenet: /home/yanjie/.cache/torch/hub/checkpoints/mobilenet_v2-6a65762b.pth
  num_classes: 21
  output_stride: 16
  num_channels: 3
  save_model_path: /home/yanjie/zyj_test/virtual-multi-view/checkpoint/


optimizer:
  name: Adam
  learning_rate: 1e-5
  weight_decay: 0.99

data_loader:
  batch_size: 2
  num_workers: 4

num_epoch: 5

render:
  img_size: 256
  camera_dist: 3
  elevation: 0
  azim_angle: 0

# Here are classes used in the benchmark
# we set background and other furnitures as one class
benchmark_labels: ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'shower curtain', 'toilet', 'sink', 'bathtub', 'otherfurniture']
valid_class_ids: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39]

visdom:
  use: True
  env: YanjieZe